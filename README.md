# üçî Restaurant AI - The Common House

An AI-powered restaurant ordering system featuring **Tobi**, a surfer-style chatbot assistant with menu awareness.

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.118+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![CI Status](https://github.com/Erics38/Tobi-the-local-server-serfing-server/actions/workflows/ci.yml/badge.svg)
![Docker Build](https://github.com/Erics38/Tobi-the-local-server-serfing-server/actions/workflows/docker.yml/badge.svg)

---

## ‚ú® Features

- ü§ñ **Menu-Aware AI Chatbot** - Tobi understands food categories, ingredients, and can recommend items
- üß† **AI-Powered by Default** - Uses local Phi-2 model for natural language understanding (2-10s)
- ‚ö° **Template Fallback** - Instant responses (<10ms) if AI unavailable or for development
- üçΩÔ∏è **Full Menu System** - Starters, Mains, Desserts, and Drinks
- üìã **Order Management** - Create and track orders with presidential birth year order numbers
- üéØ **Magic Password** - VIP treatment for special customers ("i'm on yelp")
- üíæ **SQLite Database** - Persistent order storage
- üîí **Production Ready** - Proper logging, health checks, and error handling
- üê≥ **Docker Support** - One-command deployment
- üîß **Environment-Based Config** - Easy configuration via `.env` files
- üí∞ **Zero API Costs** - Run AI models locally with no external dependencies

---

## üèóÔ∏è Infrastructure Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         User's Browser                          ‚îÇ
‚îÇ                  http://localhost:8000/static/                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ HTTP/WebSocket
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Restaurant AI (FastAPI)                      ‚îÇ
‚îÇ                         Port 8000                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Endpoints:                                                     ‚îÇ
‚îÇ  ‚Ä¢ GET  /                    - Root/Health                      ‚îÇ
‚îÇ  ‚Ä¢ GET  /menu                - Menu data                        ‚îÇ
‚îÇ  ‚Ä¢ POST /chat                - Chat with Tobi                   ‚îÇ
‚îÇ  ‚Ä¢ POST /order               - Create order                     ‚îÇ
‚îÇ  ‚Ä¢ GET  /order/{id}          - Get order status                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                               ‚îÇ
             ‚îÇ SQLite                        ‚îÇ HTTP POST
             ‚îÇ                               ‚îÇ
             ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   SQLite Database    ‚îÇ    ‚îÇ   llama-server (Optional)          ‚îÇ
‚îÇ   (data/orders.db)   ‚îÇ    ‚îÇ   Port 8080                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Orders             ‚îÇ    ‚îÇ ‚Ä¢ Phi-2 Model (1.7GB)              ‚îÇ
‚îÇ ‚Ä¢ Presidential       ‚îÇ    ‚îÇ ‚Ä¢ Natural Language Processing      ‚îÇ
‚îÇ   Order Numbers      ‚îÇ    ‚îÇ ‚Ä¢ Context: 4096 tokens             ‚îÇ
‚îÇ ‚Ä¢ Session Tracking   ‚îÇ    ‚îÇ ‚Ä¢ Response time: 2-10s             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Data Flow:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1. User sends message in chat ‚Üí FastAPI /chat endpoint
2. If USE_LOCAL_AI=true:
   ‚Üí FastAPI ‚Üí llama-server (AI generates response)
3. If USE_LOCAL_AI=false or AI unavailable:
   ‚Üí FastAPI uses template responses (instant)
4. User creates order ‚Üí FastAPI ‚Üí SQLite (stores order)
5. FastAPI returns order confirmation with presidential year number

Docker Compose Setup:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Docker Compose (docker-compose.yml)                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ ‚îÇ  app container    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ llama-server         ‚îÇ         ‚îÇ
‚îÇ ‚îÇ  (restaurant-ai)  ‚îÇ  HTTP   ‚îÇ container            ‚îÇ         ‚îÇ
‚îÇ ‚îÇ  Port: 8000       ‚îÇ         ‚îÇ Port: 8080           ‚îÇ         ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ           ‚îÇ                               ‚îÇ                     ‚îÇ
‚îÇ           ‚ñº                               ‚ñº                     ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ   ‚îÇ Volume:      ‚îÇ              ‚îÇ Volume:         ‚îÇ            ‚îÇ
‚îÇ   ‚îÇ ./data       ‚îÇ              ‚îÇ ./models        ‚îÇ            ‚îÇ
‚îÇ   ‚îÇ (orders.db)  ‚îÇ              ‚îÇ (phi-2.gguf)    ‚îÇ            ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Technology Stack:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Backend:  FastAPI (Python 3.11+)
AI:       llama.cpp + Phi-2 (GGUF format)
Database: SQLite (development) / PostgreSQL (production ready)
Frontend: HTML/JavaScript (static files)
Deploy:   Docker + Docker Compose
```

---

## üöÄ Quick Start

**Prerequisites**: Docker + 1.7GB Phi-2 model

### Step 1: Download Model (one-time)

```bash
mkdir -p models
curl -L -o models/phi-2.Q4_K_M.gguf \
  https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf
```

### Step 2: Start with Docker (AI-powered)

```bash
# Windows:
start.bat

# macOS/Linux:
chmod +x start.sh && ./start.sh

# Or manually:
docker-compose up --build -d
```

**Access**: http://localhost:8000/static/restaurant_chat.html

### Optional: Template Mode (Fast, No AI)

```bash
USE_LOCAL_AI=false docker-compose up -d
```

---

## üìÅ Project Structure

```
restaurant-ai/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI application & endpoints
‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Environment-based configuration
‚îÇ   ‚îú‚îÄ‚îÄ models.py        # Pydantic models for validation
‚îÇ   ‚îú‚îÄ‚îÄ database.py      # SQLite database operations
‚îÇ   ‚îú‚îÄ‚îÄ tobi_ai.py       # AI chatbot logic (menu-aware)
‚îÇ   ‚îî‚îÄ‚îÄ menu_data.py     # Restaurant menu data
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îî‚îÄ‚îÄ restaurant_chat.html  # Web interface
‚îú‚îÄ‚îÄ data/                # Database files (git-ignored)
‚îú‚îÄ‚îÄ logs/                # Application logs (git-ignored)
‚îú‚îÄ‚îÄ models/              # AI model files (git-ignored)
‚îú‚îÄ‚îÄ tests/               # Unit tests
‚îú‚îÄ‚îÄ .env.example         # Example environment variables
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
```

---

## üîß Configuration

All configuration is managed through environment variables. Copy `.env.example` to `.env` and customize:

```bash
# Server
HOST=0.0.0.0
PORT=8000
ENVIRONMENT=development  # development, staging, production

# Database
DATABASE_URL=sqlite:///./data/orders.db

# Restaurant
RESTAURANT_NAME=The Common House

# Features
ENABLE_MAGIC_PASSWORD=True
MAGIC_PASSWORD=i'm on yelp

# Security
SECRET_KEY=your-secret-key-here  # Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"

# Logging
LOG_LEVEL=INFO
```

---

## üì° API Endpoints

### Core Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | Root endpoint with basic info |
| `GET` | `/health` | Health check for monitoring |
| `GET` | `/menu` | Get full restaurant menu |
| `POST` | `/chat` | Chat with Tobi AI |
| `POST` | `/order` | Create a new order |
| `GET` | `/order/{order_number}` | Get order details |

### Interactive API Documentation

- **Swagger UI**: http://localhost:8000/api/docs
- **ReDoc**: http://localhost:8000/api/redoc

---

## üí¨ Chat Examples

```bash
# Ask about menu items
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What burgers do you have?"}'

# Response: "Oh dude, the House Smash Burger is awesome! It's Double patty, cheddar, caramelized onion - totally worth the $16.00. Want me to add it to your order?"

# Ask for recommendations
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What do you recommend?"}'

# VIP treatment
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hi, I'\''m on yelp"}'
```

---

## üì¶ Creating an Order

```bash
curl -X POST http://localhost:8000/order \
  -H "Content-Type: application/json" \
  -d '{
    "items": [
      {"name": "House Smash Burger", "price": 16.00, "quantity": 2},
      {"name": "Truffle Fries", "price": 12.00, "quantity": 1}
    ]
  }'

# Response:
# {
#   "success": true,
#   "order_number": 1732,  # Presidential birth year!
#   "total": 44.00,
#   "message": "Order #1732 confirmed! Your food will be ready shortly."
# }
```

---

## üß™ Testing

```bash
# Run tests (when implemented)
pytest

# Check code style
black app/
flake8 app/

# Type checking
mypy app/
```

---

## üê≥ Docker Commands

```bash
# Build and start
docker-compose up --build

# Run in background
docker-compose up -d

# View logs
docker-compose logs -f app

# Stop
docker-compose down

# Rebuild after code changes
docker-compose up --build
```

---

## üîÆ Future Enhancements

### Phase 2: Real AI Integration

Uncomment the `llama-server` section in `docker-compose.yml` to use actual LLM:

```yaml
llama-server:
  image: ghcr.io/ggerganov/llama.cpp:server
  volumes:
    - ./models:/models:ro
  command: -m /models/phi-2.Q4_K_M.gguf --host 0.0.0.0 --port 8080
```

Then update `.env`:
```bash
LLAMA_SERVER_URL=http://llama-server:8080/completion
```

### Phase 3: Database Upgrade

Switch to PostgreSQL for production:

```bash
# In .env
DATABASE_URL=postgresql://user:password@db:5432/restaurant
```

Add PostgreSQL service to `docker-compose.yml`.

---

## üõ†Ô∏è Development

### Hot Reload

The application supports hot reload in development mode:

```bash
# Automatic reload on code changes
python -m uvicorn app.main:app --reload

# Or with Docker (volume mounted in docker-compose.yml)
docker-compose up
```

### Adding New Menu Items

Edit `app/menu_data.py`:

```python
MENU_DATA = {
    "starters": [
        {"name": "New Item", "description": "Delicious!", "price": 15.00},
        # ...
    ]
}
```

---

## üìù License

MIT License - feel free to use this project for your own restaurant!

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## üôã‚Äç‚ôÇÔ∏è Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/restaurant-ai/issues)
- **Documentation**: This README and inline code comments
- **API Docs**: http://localhost:8000/api/docs

---

## üéØ Tobi's Personality

Tobi is a chill surfer dude who loves talking about food! He uses phrases like:
- "Dude", "Bro", "Yo"
- "Rad", "Sick", "Gnarly", "Killer", "Epic"
- "Stoked", "Totally", "For sure"

Try chatting with him at: http://localhost:8000/static/restaurant_chat.html

---

## üìö Documentation

- **[SETUP.md](SETUP.md)** - Complete setup guide for new users
- **[README_AI_INTEGRATION.md](../README_AI_INTEGRATION.md)** - Deep dive into AI features
- **[MIGRATION_GUIDE.md](MIGRATION_GUIDE.md)** - Upgrading from old version
- **API Docs** - http://localhost:8000/api/docs (when running)

---

**Built with ‚ù§Ô∏è using FastAPI, Python, and a touch of surfer vibes üèÑ‚Äç‚ôÇÔ∏è**
