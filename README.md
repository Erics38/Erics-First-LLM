# ğŸ” Restaurant AI - The Common House

An AI-powered restaurant ordering system featuring **Tobi**, a surfer-style chatbot assistant with menu awareness.

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.118+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

---

## âœ¨ Features

- ğŸ¤– **Menu-Aware AI Chatbot** - Tobi understands food categories, ingredients, and can recommend items
- ğŸ§  **AI-Powered by Default** - Uses local Phi-2 model for natural language understanding (2-10s)
- âš¡ **Template Fallback** - Instant responses (<10ms) if AI unavailable or for development
- ğŸ½ï¸ **Full Menu System** - Starters, Mains, Desserts, and Drinks
- ğŸ“‹ **Order Management** - Create and track orders with presidential birth year order numbers
- ğŸ¯ **Magic Password** - VIP treatment for special customers ("i'm on yelp")
- ğŸ’¾ **SQLite Database** - Persistent order storage
- ğŸ”’ **Production Ready** - Proper logging, health checks, and error handling
- ğŸ³ **Docker Support** - One-command deployment
- ğŸ”§ **Environment-Based Config** - Easy configuration via `.env` files
- ğŸ’° **Zero API Costs** - Run AI models locally with no external dependencies

---

## ğŸš€ Quick Start

**Prerequisites**: Docker + 1.7GB Phi-2 model

### Step 1: Download Model (one-time)

```bash
mkdir -p models
curl -L -o models/phi-2.Q4_K_M.gguf \
  https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf
```

### Step 2: Start with Docker (AI-powered)

```bash
# Windows:
start.bat

# macOS/Linux:
chmod +x start.sh && ./start.sh

# Or manually:
docker-compose up --build -d
```

**Access**: http://localhost:8000/static/restaurant_chat.html

### Optional: Template Mode (Fast, No AI)

```bash
USE_LOCAL_AI=false docker-compose up -d
```

---

## ğŸ“ Project Structure

```
restaurant-ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py          # FastAPI application & endpoints
â”‚   â”œâ”€â”€ config.py        # Environment-based configuration
â”‚   â”œâ”€â”€ models.py        # Pydantic models for validation
â”‚   â”œâ”€â”€ database.py      # SQLite database operations
â”‚   â”œâ”€â”€ tobi_ai.py       # AI chatbot logic (menu-aware)
â”‚   â””â”€â”€ menu_data.py     # Restaurant menu data
â”œâ”€â”€ static/
â”‚   â””â”€â”€ restaurant_chat.html  # Web interface
â”œâ”€â”€ data/                # Database files (git-ignored)
â”œâ”€â”€ logs/                # Application logs (git-ignored)
â”œâ”€â”€ models/              # AI model files (git-ignored)
â”œâ”€â”€ tests/               # Unit tests
â”œâ”€â”€ .env.example         # Example environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

All configuration is managed through environment variables. Copy `.env.example` to `.env` and customize:

```bash
# Server
HOST=0.0.0.0
PORT=8000
ENVIRONMENT=development  # development, staging, production

# Database
DATABASE_URL=sqlite:///./data/orders.db

# Restaurant
RESTAURANT_NAME=The Common House

# Features
ENABLE_MAGIC_PASSWORD=True
MAGIC_PASSWORD=i'm on yelp

# Security
SECRET_KEY=your-secret-key-here  # Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"

# Logging
LOG_LEVEL=INFO
```

---

## ğŸ“¡ API Endpoints

### Core Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | Root endpoint with basic info |
| `GET` | `/health` | Health check for monitoring |
| `GET` | `/menu` | Get full restaurant menu |
| `POST` | `/chat` | Chat with Tobi AI |
| `POST` | `/order` | Create a new order |
| `GET` | `/order/{order_number}` | Get order details |

### Interactive API Documentation

- **Swagger UI**: http://localhost:8000/api/docs
- **ReDoc**: http://localhost:8000/api/redoc

---

## ğŸ’¬ Chat Examples

```bash
# Ask about menu items
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What burgers do you have?"}'

# Response: "Oh dude, the House Smash Burger is awesome! It's Double patty, cheddar, caramelized onion - totally worth the $16.00. Want me to add it to your order?"

# Ask for recommendations
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What do you recommend?"}'

# VIP treatment
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hi, I'\''m on yelp"}'
```

---

## ğŸ“¦ Creating an Order

```bash
curl -X POST http://localhost:8000/order \
  -H "Content-Type: application/json" \
  -d '{
    "items": [
      {"name": "House Smash Burger", "price": 16.00, "quantity": 2},
      {"name": "Truffle Fries", "price": 12.00, "quantity": 1}
    ]
  }'

# Response:
# {
#   "success": true,
#   "order_number": 1732,  # Presidential birth year!
#   "total": 44.00,
#   "message": "Order #1732 confirmed! Your food will be ready shortly."
# }
```

---

## ğŸ§ª Testing

```bash
# Run tests (when implemented)
pytest

# Check code style
black app/
flake8 app/

# Type checking
mypy app/
```

---

## ğŸ³ Docker Commands

```bash
# Build and start
docker-compose up --build

# Run in background
docker-compose up -d

# View logs
docker-compose logs -f app

# Stop
docker-compose down

# Rebuild after code changes
docker-compose up --build
```

---

## ğŸ”® Future Enhancements

### Phase 2: Real AI Integration

Uncomment the `llama-server` section in `docker-compose.yml` to use actual LLM:

```yaml
llama-server:
  image: ghcr.io/ggerganov/llama.cpp:server
  volumes:
    - ./models:/models:ro
  command: -m /models/phi-2.Q4_K_M.gguf --host 0.0.0.0 --port 8080
```

Then update `.env`:
```bash
LLAMA_SERVER_URL=http://llama-server:8080/completion
```

### Phase 3: Database Upgrade

Switch to PostgreSQL for production:

```bash
# In .env
DATABASE_URL=postgresql://user:password@db:5432/restaurant
```

Add PostgreSQL service to `docker-compose.yml`.

---

## ğŸ› ï¸ Development

### Hot Reload

The application supports hot reload in development mode:

```bash
# Automatic reload on code changes
python -m uvicorn app.main:app --reload

# Or with Docker (volume mounted in docker-compose.yml)
docker-compose up
```

### Adding New Menu Items

Edit `app/menu_data.py`:

```python
MENU_DATA = {
    "starters": [
        {"name": "New Item", "description": "Delicious!", "price": 15.00},
        # ...
    ]
}
```

---

## ğŸ“ License

MIT License - feel free to use this project for your own restaurant!

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## ğŸ™‹â€â™‚ï¸ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/restaurant-ai/issues)
- **Documentation**: This README and inline code comments
- **API Docs**: http://localhost:8000/api/docs

---

## ğŸ¯ Tobi's Personality

Tobi is a chill surfer dude who loves talking about food! He uses phrases like:
- "Dude", "Bro", "Yo"
- "Rad", "Sick", "Gnarly", "Killer", "Epic"
- "Stoked", "Totally", "For sure"

Try chatting with him at: http://localhost:8000/static/restaurant_chat.html

---

## ğŸ“š Documentation

- **[SETUP.md](SETUP.md)** - Complete setup guide for new users
- **[README_AI_INTEGRATION.md](../README_AI_INTEGRATION.md)** - Deep dive into AI features
- **[MIGRATION_GUIDE.md](MIGRATION_GUIDE.md)** - Upgrading from old version
- **API Docs** - http://localhost:8000/api/docs (when running)

---

**Built with â¤ï¸ using FastAPI, Python, and a touch of surfer vibes ğŸ„â€â™‚ï¸**
